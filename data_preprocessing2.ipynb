{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "from glob import glob \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "\n",
    "import cv2 \n",
    "import gc \n",
    "import os \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from keras import layers \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "data_path = 'lung-and-colon-cancer-histopa\\ thological-images.zip' \n",
    "\n",
    "with ZipFile(data_path,'r') as zip: \n",
    "    zip.extractall() \n",
    "    print('The data set has been extracted.')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/lung_colon_image_set/lung_image_sets'\n",
    "classes = os.listdir(path) \n",
    "classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/lung_colon_image_set/lung_image_sets'\n",
    "\n",
    "for cat in classes: \n",
    "\timage_dir = f'{path}/{cat}'\n",
    "\timages = os.listdir(image_dir) \n",
    "\n",
    "\tfig, ax = plt.subplots(1, 3, figsize = (15, 5)) \n",
    "\tfig.suptitle(f'Images for {cat} category . . . .', \n",
    "\t\t\t\tfontsize = 20) \n",
    "\n",
    "\tfor i in range(3): \n",
    "\t\tk = np.random.randint(0, len(images)) \n",
    "\t\timg = np.array(Image.open(f'{path}/{cat}/{images[k]}')) \n",
    "\t\tax[i].imshow(img) \n",
    "\t\tax[i].axis('off') \n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "SPLIT = 0.2\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] \n",
    "Y = [] \n",
    "\n",
    "for i, cat in enumerate(classes): \n",
    "\timages = glob(f'{path}/{cat}/*.jpeg') \n",
    "\n",
    "for image in images: \n",
    "\timg = cv2.imread(image) \n",
    "\t\n",
    "\tX.append(cv2.resize(img, (IMG_SIZE, IMG_SIZE))) \n",
    "\tY.append(i) \n",
    "\n",
    "X = np.asarray(X) \n",
    "one_hot_encoded_Y = pd.get_dummies(Y).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split( \n",
    "X, one_hot_encoded_Y, test_size = SPLIT, random_state = 2022) \n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMG_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minception_v3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InceptionV3 \n\u001b[0;32m      3\u001b[0m pre_trained_model \u001b[38;5;241m=\u001b[39m InceptionV3( \n\u001b[1;32m----> 4\u001b[0m \tinput_shape \u001b[38;5;241m=\u001b[39m (\u001b[43mIMG_SIZE\u001b[49m, IMG_SIZE, \u001b[38;5;241m3\u001b[39m), \n\u001b[0;32m      5\u001b[0m \tweights \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      6\u001b[0m \tinclude_top \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IMG_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 \n",
    "\n",
    "pre_trained_model = InceptionV3( \n",
    "\tinput_shape = (IMG_SIZE, IMG_SIZE, 3), \n",
    "\tweights = 'imagenet', \n",
    "\tinclude_top = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pre_trained_model.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers: \n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7') \n",
    "print('last layer output shape: ', last_layer.output_shape) \n",
    "last_output = last_layer.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(last_output) \n",
    "\n",
    "x = layers.Dense(256,activation='relu')(x) \n",
    "x = layers.BatchNormalization()(x) \n",
    "\n",
    "x = layers.Dense(128,activation='relu')(x) \n",
    "x = layers.Dropout(0.3)(x) \n",
    "x = layers.BatchNormalization()(x) \n",
    "\n",
    "output = layers.Dense(3, activation='softmax')(x) \n",
    "\n",
    "model = keras.Model(pre_trained_model.input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( \n",
    "\toptimizer='adam', \n",
    "\tloss='categorical_crossentropy', \n",
    "\tmetrics=['accuracy'] \n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if logs.get('val_accuracy') > 0.90: \n",
    "            print('\\n Validation accuracy has reached upto 90%\\ so, stopping further training.') \n",
    "            self.model.stop_training = True\n",
    "\n",
    "es = EarlyStopping(patience = 3, \n",
    "\t\t\t\tmonitor = 'val_accuracy', \n",
    "\t\t\t\trestore_best_weights = True) \n",
    "\n",
    "lr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "\t\t\t\t\tpatience = 2, \n",
    "\t\t\t\t\tfactor = 0.5, \n",
    "\t\t\t\t\tverbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "\t\t\t\t\tvalidation_data = (X_val, Y_val), \n",
    "\t\t\t\t\tbatch_size = BATCH_SIZE, \n",
    "\t\t\t\t\tepochs = EPOCHS, \n",
    "\t\t\t\t\tverbose = 1, \n",
    "\t\t\t\t\tcallbacks = [es, lr, myCallback()]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history) \n",
    "history_df.loc[:,['loss','val_loss']].plot() \n",
    "history_df.loc[:,['accuracy','val_accuracy']].plot() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_val) \n",
    "\n",
    "Y_val = np.argmax(Y_val, axis=1) \n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(Y_val, Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(Y_val, Y_pred, target_names=classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
